{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Batch Processing",
   "id": "cf93b4a0c4430c96"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T13:50:39.831689Z",
     "start_time": "2024-12-01T13:50:39.829011Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from python.open_ai.functions import (\n",
    "    load_json, prepare_batch_files,\n",
    "    upload_batch_file, create_batch_job, get_batch_results\n",
    ")\n",
    "from math import ceil\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import json\n",
    "import uuid\n",
    "import glob"
   ],
   "id": "89c7e9065b06c35b",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-01T13:27:18.898721Z",
     "start_time": "2024-12-01T13:27:18.892524Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['inputs/batch_input_H8-2-1.json.jsonl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21,
   "source": [
    "directory_path = f\"raw/\"\n",
    "result_dir_path = Path(f\"outputs/\")\n",
    "result_dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load all data from files in the directory\n",
    "data_list = defaultdict(list)\n",
    "for filename in os.listdir(directory_path):\n",
    "    file_path = os.path.join(directory_path, filename)\n",
    "    if os.path.exists(os.path.join(result_dir_path, filename)):\n",
    "        continue\n",
    "\n",
    "    raw_data = load_json(file_path)\n",
    "    for i in range(ceil(len(raw_data) / 8)):\n",
    "        start = i * 8\n",
    "        end = start + 8\n",
    "        window = raw_data[start:end]\n",
    "        data_list[filename].append(window)\n",
    "\n",
    "# Provide instructions for ChatGPT\n",
    "instructions = (\n",
    "    \"Feldolgozd az alábbi adatokat egy strukturált formátumhoz ezekkel az oszlopokkal: \"\n",
    "    \"brand, product_name, price, currency, quantity, measurement, product_category, sub_categories. \"\n",
    "    \"Adj hozzá releváns alkategóriákat a névben található kulcsszavak alapján. \"\n",
    "    \"Csak JSON szöveges választ adj!. A sorokat magyar nyelven add meg.\"\n",
    ")\n",
    "\n",
    "# Prepare batch file\n",
    "files = prepare_batch_files(data_list, instructions)\n",
    "files"
   ],
   "id": "initial_id"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T13:28:28.323443Z",
     "start_time": "2024-12-01T13:28:25.914785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_jobs = []\n",
    "# Upload batch file\n",
    "for file in files:\n",
    "    batch_file = upload_batch_file(file)\n",
    "    print(f\"Batch file uploaded with ID: {batch_file.id}\")\n",
    "\n",
    "    # Create batch job\n",
    "    batch_job = create_batch_job(batch_file.id)\n",
    "    print(f\"Batch job created with ID: {batch_job.id}\")\n",
    "    batch_jobs.append(batch_job.id)\n",
    "\n",
    "    # Wait for batch to complete and retrieve results (add a polling mechanism if needed)\n",
    "    print(get_batch_results(batch_job.id))"
   ],
   "id": "3327810118302085",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch file uploaded with ID: file-S3fukTyMLUTAAEGFHupdFD\n",
      "Batch job created with ID: batch_674c647bb0cc819087a4c96937551491\n",
      "Batch job status: in_progress\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T13:42:54.844450Z",
     "start_time": "2024-12-01T13:42:54.841999Z"
    }
   },
   "cell_type": "code",
   "source": "batch_jobs =[\"batch_674c647bb0cc819087a4c96937551491\"]",
   "id": "888c4956056dd24d",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T13:42:56.224689Z",
     "start_time": "2024-12-01T13:42:56.220719Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "# Specify the file name\n",
    "import uuid\n",
    "file_name = f\"batch_jobs_{uuid.uuid4()}.json\"\n",
    "\n",
    "# Write the list to a JSON file\n",
    "try:\n",
    "    with open(file_name, 'w') as json_file:\n",
    "        json.dump(batch_jobs, json_file, indent=4)  # Use indent for a pretty-printed JSON\n",
    "    print(f\"JSON file '{file_name}' created successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ],
   "id": "de13329bac64e9b1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file 'batch_jobs_9a717cb7-6973-4a8a-89d3-b5960e3f3bfb.json' created successfully!\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T13:51:39.445564Z",
     "start_time": "2024-12-01T13:51:39.203039Z"
    }
   },
   "cell_type": "code",
   "source": "get_batch_results(\"batch_674c647bb0cc819087a4c96937551491\")",
   "id": "3630f496dcebafb2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Batch job status: in_progress'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T13:47:46.444352Z",
     "start_time": "2024-12-01T13:47:46.439214Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to find the JSON file with the specific naming pattern\n",
    "def find_batch_jobs_file():\n",
    "    # Use a glob pattern to find files that match \"batch_jobs_<UUID>.json\"\n",
    "    json_files = glob.glob(\"batch_jobs_*.json\")\n",
    "    for file in json_files:\n",
    "        try:\n",
    "            # Validate that the file name contains a valid UUID\n",
    "            uuid_part = file.split(\"_\")[2].split(\".\")[0]\n",
    "            uuid.UUID(uuid_part)\n",
    "            return file\n",
    "        except (IndexError, ValueError):\n",
    "            continue\n",
    "    return None\n",
    "\n",
    "# Load the list back from the JSON file\n",
    "try:\n",
    "    file_name = find_batch_jobs_file()\n",
    "    if file_name:\n",
    "        with open(file_name, 'r') as json_file:\n",
    "            batch_jobs = json.load(json_file)\n",
    "        print(f\"Loaded data from '{file_name}':\")\n",
    "        print(batch_jobs)\n",
    "    else:\n",
    "        print(\"No valid 'batch_jobs' JSON file found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ],
   "id": "505680c1497991ce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from 'batch_jobs_9a717cb7-6973-4a8a-89d3-b5960e3f3bfb.json':\n",
      "['batch_674c647bb0cc819087a4c96937551491']\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c063bdee9914d232"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
